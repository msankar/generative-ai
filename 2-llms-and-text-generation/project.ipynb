{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "TODO: In this cell, write an explanation of which dataset you have chosen and why it is appropriate for this task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a675c1",
   "metadata": {},
   "source": [
    "Building a custom OpenAI chatbot with ML Driven Prompt Engineering I wanted to ask questions about British royal events that happened in 2023 particularly about King Charles III's coronation. So I picked the 2023 Wiki data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "TODO: In the cells below, load your chosen dataset into a `pandas` dataframe with a column named `\"text\"`. This column should contain all of your text data, separated into at least 20 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_base = \"https://openai.vocareum.com/v1\"\n",
    "openai.api_key = \"YOUR_API_KEY\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17e76928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a595980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coronation of King Charles III took place at Westminster Abbey in London, England on July 11, 2022.\n"
     ]
    }
   ],
   "source": [
    "coronation_prompt = \"\"\"\n",
    "Question: \"Where did King Charles III coronation happen?\"\n",
    "Answer:\n",
    "\"\"\"\n",
    "initial_coronation_answer = openai.Completion.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=coronation_prompt,\n",
    "    max_tokens=150\n",
    ")[\"choices\"][0][\"text\"].strip()\n",
    "print(initial_coronation_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acb3a9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "King Charles' queen is Queen Camilla, Duchess of Cornwall.\n"
     ]
    }
   ],
   "source": [
    "queen_prompt = \"\"\"\n",
    "Question: \"Who is King Charles' queen?\"\n",
    "Answer:\n",
    "\"\"\"\n",
    "initial_queen_answer = openai.Completion.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=queen_prompt,\n",
    "    max_tokens=150\n",
    ")[\"choices\"][0][\"text\"].strip()\n",
    "print(initial_queen_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bc7d506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>– 2023 (MMXXIII) was a common year starting o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>– Catastrophic natural disasters in 2023 incl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>– The Russian invasion of Ukraine and Myanmar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>– A banking crisis resulted in the collapse o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>January 1 – Croatia adopts the euro and joins ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Economics – Claudia Goldin, for her empirical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Literature – Jon Fosse, for his innovative pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Peace – Narges Mohammadi, for her works on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Physics – Pierre Agostini, Ferenc Krausz &amp; Ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Physiology or Medicine – Katalin Karikó &amp; Drew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0     – 2023 (MMXXIII) was a common year starting o...\n",
       "1     – Catastrophic natural disasters in 2023 incl...\n",
       "2     – The Russian invasion of Ukraine and Myanmar...\n",
       "3     – A banking crisis resulted in the collapse o...\n",
       "11   January 1 – Croatia adopts the euro and joins ...\n",
       "..                                                 ...\n",
       "324  Economics – Claudia Goldin, for her empirical ...\n",
       "325  Literature – Jon Fosse, for his innovative pla...\n",
       "326  Peace – Narges Mohammadi, for her works on the...\n",
       "327  Physics – Pierre Agostini, Ferenc Krausz & Ann...\n",
       "328  Physiology or Medicine – Katalin Karikó & Drew...\n",
       "\n",
       "[226 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Step 1: Prepare Dataset\n",
    "# Loading and Wrangling Data\n",
    "# **The data should be loaded into a pandas `DataFrame` called `df` where each row represents a text sample, and there is only one column, `\"text\"`, which contains the raw text data.**\n",
    "# In this particular case we are collecting data from [the Wikipedia page for the year 2023](https://en.wikipedia.org/wiki/2023) and performing some data wrangling to get it into the appropriate format.\n",
    "\n",
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Set a proper User-Agent header (required by Wikipedia)\n",
    "headers = {\n",
    "    'User-Agent': 'MyResearchBot/1.0 (your-email@example.com)'  # Replace with your actual contact info\n",
    "}\n",
    "\n",
    "# Get the Wikipedia page for \"2023\"\n",
    "resp = requests.get(\n",
    "    \"https://en.wikipedia.org/w/api.php?action=query&prop=extracts&exlimit=1&titles=2023&explaintext=1&formatversion=2&format=json\",\n",
    "    headers=headers\n",
    ")\n",
    "\n",
    "# Check if the request was successful\n",
    "if resp.status_code != 200:\n",
    "    raise Exception(f\"Request failed with status code: {resp.status_code}\")\n",
    "\n",
    "# Load page text into a dataframe\n",
    "df = pd.DataFrame()\n",
    "df[\"text\"] = resp.json()[\"query\"][\"pages\"][0][\"extract\"].split(\"\\n\")\n",
    "\n",
    "# Clean up text to remove empty lines and headings\n",
    "df = df[(df[\"text\"].str.len() > 0) & (~df[\"text\"].str.startswith(\"==\"))]\n",
    "\n",
    "# In some cases dates are used as headings instead of being part of the\n",
    "# text sample; adjust so dated text samples start with dates\n",
    "prefix = \"\"\n",
    "for (i, row) in df.iterrows():\n",
    "    # If the row already has \" – \", it already has the needed date prefix\n",
    "    if \" – \" not in row[\"text\"]:\n",
    "        try:\n",
    "            # If the row's text is a date, set it as the new prefix\n",
    "            parse(row[\"text\"])\n",
    "            prefix = row[\"text\"]\n",
    "        except:\n",
    "            # If the row's text isn't a date, add the prefix\n",
    "            df.at[i, \"text\"] = prefix + \" – \" + row[\"text\"]\n",
    "            \n",
    "df = df[df[\"text\"].str.contains(\" – \")]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb4e557",
   "metadata": {},
   "source": [
    "Generating Embeddings\n",
    "We'll use the Embedding tooling from OpenAI documentation here to create vectors representing each row of our custom dataset.\n",
    "\n",
    "In order to avoid a RateLimitError we'll send our data in batches to the Embedding.create function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37bd9342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>– 2023 (MMXXIII) was a common year starting o...</td>\n",
       "      <td>[0.0036799046210944653, -0.0138942189514637, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>– Catastrophic natural disasters in 2023 incl...</td>\n",
       "      <td>[-0.022169683128595352, -0.00321850529871881, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>– The Russian invasion of Ukraine and Myanmar...</td>\n",
       "      <td>[-0.01289023831486702, -0.011169254779815674, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>– A banking crisis resulted in the collapse o...</td>\n",
       "      <td>[-0.03203907236456871, -0.011590203270316124, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>January 1 – Croatia adopts the euro and joins ...</td>\n",
       "      <td>[0.01309617143124342, -0.020668700337409973, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Economics – Claudia Goldin, for her empirical ...</td>\n",
       "      <td>[-0.01694655232131481, -0.007920671254396439, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Literature – Jon Fosse, for his innovative pla...</td>\n",
       "      <td>[-0.009484800510108471, 0.01768663339316845, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Peace – Narges Mohammadi, for her works on the...</td>\n",
       "      <td>[-0.013250409625470638, -0.012954494915902615,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Physics – Pierre Agostini, Ferenc Krausz &amp; Ann...</td>\n",
       "      <td>[-0.02043410949409008, 0.014828776940703392, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Physiology or Medicine – Katalin Karikó &amp; Drew...</td>\n",
       "      <td>[-0.009041665121912956, 0.004211914259940386, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0     – 2023 (MMXXIII) was a common year starting o...   \n",
       "1     – Catastrophic natural disasters in 2023 incl...   \n",
       "2     – The Russian invasion of Ukraine and Myanmar...   \n",
       "3     – A banking crisis resulted in the collapse o...   \n",
       "11   January 1 – Croatia adopts the euro and joins ...   \n",
       "..                                                 ...   \n",
       "324  Economics – Claudia Goldin, for her empirical ...   \n",
       "325  Literature – Jon Fosse, for his innovative pla...   \n",
       "326  Peace – Narges Mohammadi, for her works on the...   \n",
       "327  Physics – Pierre Agostini, Ferenc Krausz & Ann...   \n",
       "328  Physiology or Medicine – Katalin Karikó & Drew...   \n",
       "\n",
       "                                            embeddings  \n",
       "0    [0.0036799046210944653, -0.0138942189514637, -...  \n",
       "1    [-0.022169683128595352, -0.00321850529871881, ...  \n",
       "2    [-0.01289023831486702, -0.011169254779815674, ...  \n",
       "3    [-0.03203907236456871, -0.011590203270316124, ...  \n",
       "11   [0.01309617143124342, -0.020668700337409973, 0...  \n",
       "..                                                 ...  \n",
       "324  [-0.01694655232131481, -0.007920671254396439, ...  \n",
       "325  [-0.009484800510108471, 0.01768663339316845, 0...  \n",
       "326  [-0.013250409625470638, -0.012954494915902615,...  \n",
       "327  [-0.02043410949409008, 0.014828776940703392, 0...  \n",
       "328  [-0.009041665121912956, 0.004211914259940386, ...  \n",
       "\n",
       "[226 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in range(0, len(df), batch_size):\n",
    "    # Send text data to OpenAI model to get embeddings\n",
    "    response = openai.Embedding.create(\n",
    "        input=df.iloc[i:i+batch_size][\"text\"].tolist(),\n",
    "        engine=EMBEDDING_MODEL_NAME\n",
    "    )\n",
    "    \n",
    "    # Add embeddings to list\n",
    "    embeddings.extend([data[\"embedding\"] for data in response[\"data\"]])\n",
    "\n",
    "# Add embeddings list to dataframe\n",
    "df[\"embeddings\"] = embeddings\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb1a3385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "494a5ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  embeddings.csv  project.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aac5c0",
   "metadata": {},
   "source": [
    "Step 2: Create a Function that Finds Related Pieces of Text for a Given Question\n",
    "What we are implementing here is similar to a search engine or recommendation algorithm. We want to sort all of the rows of our dataset from least relevant to most relevant.\n",
    "\n",
    "This will use the embeddings that we generated previously in order to compare the vectorized version of our question to the vectorized versions of the rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b38f5172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding, distances_from_embeddings\n",
    "\n",
    "def get_rows_sorted_by_relevance(question, df):\n",
    "    \"\"\"\n",
    "    Function that takes in a question string and a dataframe containing\n",
    "    rows of text and associated embeddings, and returns that dataframe\n",
    "    sorted from least to most relevant for that question\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get embeddings for the question text\n",
    "    question_embeddings = get_embedding(question, engine=EMBEDDING_MODEL_NAME)\n",
    "    \n",
    "    # Make a copy of the dataframe and add a \"distances\" column containing\n",
    "    # the cosine distances between each row's embeddings and the\n",
    "    # embeddings of the question\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"distances\"] = distances_from_embeddings(\n",
    "        question_embeddings,\n",
    "        df_copy[\"embeddings\"].values,\n",
    "        distance_metric=\"cosine\"\n",
    "    )\n",
    "    \n",
    "    # Sort the copied dataframe by the distances and return it\n",
    "    # (shorter distance = more relevant so we sort in ascending order)\n",
    "    df_copy.sort_values(\"distances\", ascending=True, inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2146bb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>May 6 – The coronation of Charles III and Cami...</td>\n",
       "      <td>[0.004555157385766506, -0.0024165711365640163,...</td>\n",
       "      <td>0.121887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>December 31 – Queen Margrethe II of Denmark an...</td>\n",
       "      <td>[-0.006673671770840883, -0.02460246905684471, ...</td>\n",
       "      <td>0.227244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>January 5 – The funeral of Pope Benedict XVI i...</td>\n",
       "      <td>[0.007029644679278135, 0.002505552489310503, -...</td>\n",
       "      <td>0.232392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>November 23 – Riots broke out in Dublin, Irela...</td>\n",
       "      <td>[-0.003895672271028161, -0.0005883423145860434...</td>\n",
       "      <td>0.243534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>January 20 – The Parliament of Trinidad and To...</td>\n",
       "      <td>[-0.003036879003047943, -0.005730754230171442,...</td>\n",
       "      <td>0.247604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Peace – Narges Mohammadi, for her works on the...</td>\n",
       "      <td>[-0.013250409625470638, -0.012954494915902615,...</td>\n",
       "      <td>0.323895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>December 6 – Google DeepMind releases the Gemi...</td>\n",
       "      <td>[-0.022914431989192963, 0.011136173270642757, ...</td>\n",
       "      <td>0.324059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>January 21 – Tigray War: Eritrean forces withd...</td>\n",
       "      <td>[-0.0053468444384634495, -0.012855730019509792...</td>\n",
       "      <td>0.325588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>October 11 – ExxonMobil announces it will acqu...</td>\n",
       "      <td>[-0.009091373533010483, -0.0194711834192276, 0...</td>\n",
       "      <td>0.332023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>July 14 – SAG-AFTRA announces it will begin a ...</td>\n",
       "      <td>[-0.008810816332697868, -0.035321760922670364,...</td>\n",
       "      <td>0.333600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "124  May 6 – The coronation of Charles III and Cami...   \n",
       "302  December 31 – Queen Margrethe II of Denmark an...   \n",
       "12   January 5 – The funeral of Pope Benedict XVI i...   \n",
       "280  November 23 – Riots broke out in Dublin, Irela...   \n",
       "23   January 20 – The Parliament of Trinidad and To...   \n",
       "..                                                 ...   \n",
       "326  Peace – Narges Mohammadi, for her works on the...   \n",
       "288  December 6 – Google DeepMind releases the Gemi...   \n",
       "26   January 21 – Tigray War: Eritrean forces withd...   \n",
       "248  October 11 – ExxonMobil announces it will acqu...   \n",
       "182  July 14 – SAG-AFTRA announces it will begin a ...   \n",
       "\n",
       "                                            embeddings  distances  \n",
       "124  [0.004555157385766506, -0.0024165711365640163,...   0.121887  \n",
       "302  [-0.006673671770840883, -0.02460246905684471, ...   0.227244  \n",
       "12   [0.007029644679278135, 0.002505552489310503, -...   0.232392  \n",
       "280  [-0.003895672271028161, -0.0005883423145860434...   0.243534  \n",
       "23   [-0.003036879003047943, -0.005730754230171442,...   0.247604  \n",
       "..                                                 ...        ...  \n",
       "326  [-0.013250409625470638, -0.012954494915902615,...   0.323895  \n",
       "288  [-0.022914431989192963, 0.011136173270642757, ...   0.324059  \n",
       "26   [-0.0053468444384634495, -0.012855730019509792...   0.325588  \n",
       "248  [-0.009091373533010483, -0.0194711834192276, 0...   0.332023  \n",
       "182  [-0.008810816332697868, -0.035321760922670364,...   0.333600  \n",
       "\n",
       "[226 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's test that out for questions - Example 1\n",
    "get_rows_sorted_by_relevance(\"Where did King Charles III coronation happen?\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a397dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>May 6 – The coronation of Charles III and Cami...</td>\n",
       "      <td>[0.004555157385766506, -0.0024165711365640163,...</td>\n",
       "      <td>0.149228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>December 31 – Queen Margrethe II of Denmark an...</td>\n",
       "      <td>[-0.006673671770840883, -0.02460246905684471, ...</td>\n",
       "      <td>0.191773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>January 20 – The Parliament of Trinidad and To...</td>\n",
       "      <td>[-0.003036879003047943, -0.005730754230171442,...</td>\n",
       "      <td>0.241233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>November 27 –  After forming a coalition Gover...</td>\n",
       "      <td>[-0.0056718578562140465, -0.005239285994321108...</td>\n",
       "      <td>0.251400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>January 25 – Chris Hipkins succeeds Jacinda Ar...</td>\n",
       "      <td>[-0.01631171815097332, 0.012749671004712582, -...</td>\n",
       "      <td>0.255367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>February 6 – A 7.8 Mww earthquake strikes sout...</td>\n",
       "      <td>[-0.0024857702665030956, -0.017595678567886353...</td>\n",
       "      <td>0.327867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>January 21 – Tigray War: Eritrean forces withd...</td>\n",
       "      <td>[-0.0053468444384634495, -0.012855730019509792...</td>\n",
       "      <td>0.328582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>March 31 – April 1 – A historic and widespread...</td>\n",
       "      <td>[-0.03209320455789566, -0.02319134585559368, -...</td>\n",
       "      <td>0.329385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>July 3 – In the largest incursion by Israel in...</td>\n",
       "      <td>[-0.0222729854285717, 0.006456935778260231, 0....</td>\n",
       "      <td>0.333539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>October 25 – Hurricane Otis, an eastern Pacifi...</td>\n",
       "      <td>[-0.034518156200647354, -0.012755007483065128,...</td>\n",
       "      <td>0.336067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "124  May 6 – The coronation of Charles III and Cami...   \n",
       "302  December 31 – Queen Margrethe II of Denmark an...   \n",
       "23   January 20 – The Parliament of Trinidad and To...   \n",
       "282  November 27 –  After forming a coalition Gover...   \n",
       "27   January 25 – Chris Hipkins succeeds Jacinda Ar...   \n",
       "..                                                 ...   \n",
       "46   February 6 – A 7.8 Mww earthquake strikes sout...   \n",
       "26   January 21 – Tigray War: Eritrean forces withd...   \n",
       "88   March 31 – April 1 – A historic and widespread...   \n",
       "171  July 3 – In the largest incursion by Israel in...   \n",
       "260  October 25 – Hurricane Otis, an eastern Pacifi...   \n",
       "\n",
       "                                            embeddings  distances  \n",
       "124  [0.004555157385766506, -0.0024165711365640163,...   0.149228  \n",
       "302  [-0.006673671770840883, -0.02460246905684471, ...   0.191773  \n",
       "23   [-0.003036879003047943, -0.005730754230171442,...   0.241233  \n",
       "282  [-0.0056718578562140465, -0.005239285994321108...   0.251400  \n",
       "27   [-0.01631171815097332, 0.012749671004712582, -...   0.255367  \n",
       "..                                                 ...        ...  \n",
       "46   [-0.0024857702665030956, -0.017595678567886353...   0.327867  \n",
       "26   [-0.0053468444384634495, -0.012855730019509792...   0.328582  \n",
       "88   [-0.03209320455789566, -0.02319134585559368, -...   0.329385  \n",
       "171  [-0.0222729854285717, 0.006456935778260231, 0....   0.333539  \n",
       "260  [-0.034518156200647354, -0.012755007483065128,...   0.336067  \n",
       "\n",
       "[226 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's test that out for questions - Example 2\n",
    "get_rows_sorted_by_relevance(\"Who is King Charles' queen?\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Query Completion\n",
    "\n",
    "TODO: In the cells below, compose a custom query using your chosen dataset and retrieve results from an OpenAI `Completion` model. You may copy and paste any useful code from the course materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "582f0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create a Function that Composes a Text Prompt\n",
    "# \n",
    "# Building on that sorted list of rows, we're going to select the create a text prompt that provides context to a `Completion` model in order to help it answer a question. The outline of the prompt looks like this:\n",
    "\n",
    "# ```\n",
    "# Answer the question based on the context below, and if the\n",
    "# question can't be answered based on the context, say \"I don't\n",
    "# know\"\n",
    "# \n",
    "# Context:\n",
    "# \n",
    "# {context}\n",
    "# \n",
    "# ---\n",
    "# \n",
    "# Question: {question}\n",
    "# Answer:\n",
    "# ```\n",
    "# We want to fit as much of our dataset as possible into the \"context\" part of the prompt without exceeding the number of tokens allowed by the `Completion` model, which is currently 4,000. So we'll loop over the dataset, counting the tokens as we go, and stop when we hit the limit. Then we'll join that list of text data into a single string and add it to the prompt.\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "def create_prompt(question, df, max_token_count):\n",
    "    \"\"\"\n",
    "    Given a question and a dataframe containing rows of text and their\n",
    "    embeddings, return a text prompt to send to a Completion model\n",
    "    \"\"\"\n",
    "    # Create a tokenizer that is designed to align with our embeddings\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    \n",
    "    # Count the number of tokens in the prompt template and question\n",
    "    prompt_template = \"\"\"\n",
    "Answer the question based on the context below, and if the question\n",
    "can't be answered based on the context, say \"I don't know\"\n",
    "\n",
    "Context: \n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    current_token_count = len(tokenizer.encode(prompt_template)) + \\\n",
    "                            len(tokenizer.encode(question))\n",
    "    \n",
    "    context = []\n",
    "    for text in get_rows_sorted_by_relevance(question, df)[\"text\"].values:\n",
    "        \n",
    "        # Increase the counter based on the number of tokens in this row\n",
    "        text_token_count = len(tokenizer.encode(text))\n",
    "        current_token_count += text_token_count\n",
    "        \n",
    "        # Add the row of text to the list if we haven't exceeded the max\n",
    "        if current_token_count <= max_token_count:\n",
    "            context.append(text)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ded3801",
   "metadata": {},
   "source": [
    "Now let's test that out! We'll use a max_token_count below the actual limit just to keep the output shorter and more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13f2dcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below, and if the question\n",
      "can't be answered based on the context, say \"I don't know\"\n",
      "\n",
      "Context: \n",
      "\n",
      "May 6 – The coronation of Charles III and Camilla as King and Queen of the United Kingdom and the other Commonwealth realms is held in Westminster Abbey, London.\n",
      "\n",
      "###\n",
      "\n",
      "December 31 – Queen Margrethe II of Denmark announces her abdication effective January 14, 2024, after 52 years on the throne.\n",
      "\n",
      "###\n",
      "\n",
      "January 20 – The Parliament of Trinidad and Tobago elects former senate president, minister and lawyer Christine Kangaloo as president in a 48–22 vote.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Who is King Charles queen?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(create_prompt(\"Who is King Charles queen?\", df, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c403f543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below, and if the question\n",
      "can't be answered based on the context, say \"I don't know\"\n",
      "\n",
      "Context: \n",
      "\n",
      "May 6 – The coronation of Charles III and Camilla as King and Queen of the United Kingdom and the other Commonwealth realms is held in Westminster Abbey, London.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Where did King Charles III coronation happen?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(create_prompt(\"Where did King Charles III coronation happen?\", df, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a40150a",
   "metadata": {},
   "source": [
    "Step 4: Create a Function that Answers a Question¶\n",
    "Our final step is to send that text prompt to a Completion model and parse the model output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e235427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "def answer_question(\n",
    "    question, df, max_prompt_tokens=1800, max_answer_tokens=150\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a question, a dataframe containing rows of text, and a maximum\n",
    "    number of desired tokens in the prompt and response, return the\n",
    "    answer to the question according to an OpenAI Completion model\n",
    "    \n",
    "    If the model produces an error, return an empty string\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = create_prompt(question, df, max_prompt_tokens)\n",
    "    \n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=COMPLETION_MODEL_NAME,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_answer_tokens\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fa6434",
   "metadata": {},
   "source": [
    "Now test it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30ffd298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coronation of King Charles III took place in Westminster Abbey, London.\n"
     ]
    }
   ],
   "source": [
    "custom_coronation_answer = answer_question(\"Where did King Charles III coronation happen?\", df)\n",
    "print(custom_coronation_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68694c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camilla\n"
     ]
    }
   ],
   "source": [
    "custom_queen_answer = answer_question(\"Who is King Charles queen?\", df)\n",
    "print(custom_queen_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration\n",
    "\n",
    "TODO: In the cells below, demonstrate the performance of your custom query using at least 2 questions. For each question, show the answer from a basic `Completion` model query as well as the answer from your custom query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4901c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "King Charles III's coronation took place at Westminster Abbey in London, England.\n"
     ]
    }
   ],
   "source": [
    "coronation_prompt = \"\"\"\n",
    "Question: \"Where did King Charles III coronation happen?\"\n",
    "Answer:\n",
    "\"\"\"\n",
    "initial_coronation_answer = openai.Completion.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=coronation_prompt,\n",
    "    max_tokens=150\n",
    ")[\"choices\"][0][\"text\"].strip()\n",
    "print(initial_coronation_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fa3faf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coronation of King Charles III and Camilla took place at Westminster Abbey in London.\n"
     ]
    }
   ],
   "source": [
    "custom_coronation_answer = answer_question(\"Where did King Charles III coronation happen?\", df)\n",
    "print(custom_coronation_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f646989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "King Charles does not currently have a queen, as he has not been married. His mother, Queen Elizabeth II, is the current monarch of England.\n"
     ]
    }
   ],
   "source": [
    "cost_prompt = \"\"\"\n",
    "Question: \"Who is King Charles' queen?\"\n",
    "Answer:\n",
    "\"\"\"\n",
    "initial_cost_answer = openai.Completion.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=cost_prompt,\n",
    "    max_tokens=150\n",
    ")[\"choices\"][0][\"text\"].strip()\n",
    "print(initial_cost_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11c07a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queen Camilla\n"
     ]
    }
   ],
   "source": [
    "custom_cost_answer = answer_question(\"Who is King Charles' queen?\", df)\n",
    "print(custom_cost_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaffc54",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "\n",
    "The custom prompt questions came back with the correct answers for the following reasons.\n",
    "The model responded with the correct information when we provided it a relevant dataset. In this case wiki page of 2023 which was relevant to King Charles III inauguration.\n",
    "The Large Language Model we chose is not trained with data beyond 2022. So it is not aware of King Charles' coronation. After providing the relevant dataset it is able to come back with right answers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
